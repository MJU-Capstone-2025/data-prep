import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# 1. data load
data = pd.read_csv('../data/preprocessed/weather_with_lag.csv')
label = pd.read_csv('../data/preprocessed/coffee_label.csv')
print(f"1. ë°ì´í„° ë¡œë“œ: {data.shape}\n")

# 2. ì»¬ëŸ¼ ë¶„ë¥˜
categorical_cols = data.select_dtypes(include=['object']).columns.tolist()
categorical_cols = [col for col in categorical_cols if col != 'Date']
numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns.tolist()

# 3. split data
train_data = data[(data['Date'] >= '2020-01-01') & (data['Date'] <= '2024-02-28')].copy()
valid_data = data[(data['Date'] >= '2024-02-29') & (data['Date'] <= '2025-02-28')].copy()
test_data  = data[(data['Date'] >= '2025-03-01') & (data['Date'] <= '2025-03-23')].copy()

# NaN ì²˜ë¦¬
lag_cols = [col for col in test_data.columns if 'lag' in col]
exclude_from_nan = lag_cols + ['locationName', 'season_tag', 'days_until_harvest']
non_lag_weather_cols = [col for col in numerical_cols if col not in exclude_from_nan]
for col in non_lag_weather_cols:
    if test_data[col].dtype == 'int64':
        test_data[col] = test_data[col].astype(float)
    test_data[col] = np.nan

# 4. label ë¶„ë¦¬
label['Date'] = pd.to_datetime(label['Date'])
train_label = label[(label['Date'] >= '2015-01-02') & (label['Date'] <= '2024-02-28')].copy()
valid_label = label[(label['Date'] >= '2024-02-29') & (label['Date'] <= '2025-02-28')].copy()
test_label  = label[(label['Date'] >= '2025-03-01') & (label['Date'] <= '2025-03-23')].copy()

# 5. train merge
train_data['Date'] = pd.to_datetime(train_data['Date'])
train_label['Date'] = pd.to_datetime(train_label['Date'])
train = pd.merge(train_data, train_label, on="Date", how="inner")
X_train = train.drop(columns=["Date", "Coffee_Price", "Coffee_Price_Return"])
y_train = train["Coffee_Price"]

# 6. valid set
X_valid = valid_data.drop(columns=["Date"])
y_valid = valid_label["Coffee_Price"].values

# 7. OneHotEncoder
preprocessor = ColumnTransformer(
    transformers=[("cat", OneHotEncoder(handle_unknown="ignore"), categorical_cols)],
    remainder="passthrough"
)

# 8. ëª¨ë¸ í•™ìŠµ
model = RandomForestRegressor(
    random_state=42,
    max_features='sqrt',
    n_estimators=300,
    n_jobs=-1
)
pipeline = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", model)
])
print("ëª¨ë¸ í•™ìŠµì¤‘...")
pipeline.fit(X_train, y_train)
print("ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")

# 9. valid ì˜ˆì¸¡
valid_preds = pipeline.predict(X_valid)
valid_data["Predicted_Price"] = valid_preds
pred_daily = valid_data.groupby("Date")["Predicted_Price"].mean().reset_index()
pred_daily["Date"] = pd.to_datetime(pred_daily["Date"])
pred_daily = pd.merge(pred_daily, valid_label, on="Date", how="left")

# 9-1. ì¼ë³„ ê°€ì¤‘ì¹˜ ì ìš© (1.0 â†’ 1.1 ì„ í˜• ì¦ê°€)
valid_weights = np.linspace(1.0, 2.0, len(pred_daily))
pred_daily["Predicted_Price_Weighted"] = pred_daily["Predicted_Price"] * valid_weights

# ì‹œì‘ ê°€ê²© ë§ì¶”ê¸° (valid)
true_start_valid = pred_daily["Coffee_Price"].iloc[0]
pred_start_valid = pred_daily["Predicted_Price_Weighted"].iloc[0]
scaling_valid = true_start_valid / pred_start_valid
pred_daily["Predicted_Price_Adjusted"] = pred_daily["Predicted_Price_Weighted"] * scaling_valid

# 10. valid ì„±ëŠ¥
rmse = mean_squared_error(pred_daily["Coffee_Price"], pred_daily["Predicted_Price_Adjusted"])
r2 = r2_score(pred_daily["Coffee_Price"], pred_daily["Predicted_Price_Adjusted"])
print("\nğŸ“Š ê²€ì¦ ì„±ëŠ¥ (ë³´ì • + ê°€ì¤‘ì¹˜):")
print(f"RMSE : {rmse:.5f}")
print(f"RÂ²   : {r2:.5f}")

# 11. valid ì‹œê°í™”
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False
plt.figure(figsize=(14, 6))
sns.lineplot(data=pred_daily, x="Date", y="Coffee_Price", label="True Price")
sns.lineplot(data=pred_daily, x="Date", y="Predicted_Price_Adjusted", label="Predicted Price (Adjusted + Weighted)")
plt.title("ê²€ì¦ ê¸°ê°„ ì»¤í”¼ ê°€ê²© ì˜ˆì¸¡ ê²°ê³¼", fontsize=16)
plt.xlabel("Date")
plt.ylabel("Coffee Price (USD)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# 12. test ì˜ˆì¸¡
X_test = test_data.drop(columns=["Date"])
test_preds = pipeline.predict(X_test)
test_data["Predicted_Price"] = test_preds
test_daily = test_data.groupby("Date")["Predicted_Price"].mean().reset_index()
test_daily["Date"] = pd.to_datetime(test_daily["Date"])
test_daily = pd.merge(test_daily, test_label, on="Date", how="left")

# 12-1. ê°€ì¤‘ì¹˜ ì ìš© ì•ˆí•¨ test ê¸°ê°„ì€ ì§§ì•„ì„œ
test_weights = np.linspace(1.0, 1.1, len(test_daily))
test_daily["Predicted_Price_Weighted"] = test_daily["Predicted_Price"]

# ì‹œì‘ ê°€ê²© ë³´ì • (test)
true_start_test = test_daily["Coffee_Price"].iloc[0]
raw_start_test = test_daily["Predicted_Price_Weighted"].iloc[0]
scaling_test = true_start_test / raw_start_test
test_daily["Predicted_Price_Adjusted"] = test_daily["Predicted_Price_Weighted"] * scaling_test

# í•˜ë£¨ shift
test_daily["Predicted_Price_Adjusted_Shifted"] = test_daily["Predicted_Price_Adjusted"].shift(-1)

# 13. test ì„±ëŠ¥
rmse_test = mean_squared_error(test_daily["Coffee_Price"], test_daily["Predicted_Price_Adjusted"])
r2_test = r2_score(test_daily["Coffee_Price"], test_daily["Predicted_Price_Adjusted"])
print("\nğŸ“Š í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ (ë³´ì • + ê°€ì¤‘ì¹˜):")
print(f"Test RMSE : {rmse_test:.5f}")
print(f"Test RÂ²   : {r2_test:.5f}")

# 14. test ì‹œê°í™”
plt.figure(figsize=(14, 6))
sns.lineplot(data=test_daily[:-1], x="Date", y="Coffee_Price", label="True Price")
sns.lineplot(data=test_daily[:-1], x="Date", y="Predicted_Price_Adjusted_Shifted", label="Predicted Price (Shifted + Weighted)")
plt.title("í…ŒìŠ¤íŠ¸ ê¸°ê°„ ì»¤í”¼ ê°€ê²© ì˜ˆì¸¡ ê²°ê³¼", fontsize=16)
plt.xlabel("Date")
plt.ylabel("Coffee Price (USD)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
